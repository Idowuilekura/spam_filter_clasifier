{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project : Building a Spam Filter with Niave Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal in this project is to build a spam filter for SMS messages. To classify messages as spam or non-spam. To \"teach\" the computer how to classify messages, we will use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans.\n",
    "\n",
    "The dataset was put togetther by Tiago A. Almedia and Jose Maria Gomez Hidalgo, and it can be downloaded from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where the author's papers are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_spam_dataset = pd.read_csv('SMSSpamCollection',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sms_spam_dataset.columns = ['Label','SMS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-ham label means the message is not spam\n",
    "spam label means the message is spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.406317300789663"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_dataset[sms_spam_dataset['Label']=='spam'].shape[0]/sms_spam_dataset.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.59368269921033"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam_dataset[sms_spam_dataset['Label']=='ham'].shape[0]/sms_spam_dataset.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "Label    5572 non-null object\n",
      "SMS      5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sms_spam_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see that the percentage of spam messages in the dataset is about 13% while messages that are not spam are about 87%. It seems we have more messages that are not spam than those that are spam. This makes the sample representative since in practice most messages that people receive are ham.Also we could see that there are no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to split our dataset into a training and a test set, where the training set accounts for 80% of the data, and the test set for the remaining 20%. After building our spam filte, wee need to test it with data from the dataset which have not been used to train the data( hence the need to have a separated data from the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomize the dataset\n",
    "randomized_data = sms_spam_dataset.sample(frac=1,random_state=1)\n",
    "# Calculating index forsplit \n",
    "train_test_index = round(len(randomized_data)*0.8)\n",
    "# Training/ Test split\n",
    "train_set = randomized_data[:train_test_index].reset_index(drop=True)\n",
    "test_set = randomized_data[train_test_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to analyze the percentge of spam and ham messages in the training and test sets. We expect the percentages to be clolsoe to what we have in the full dataset, where about 87% of the messages are ham, and the remaining 13% are spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test_set[test_set['Label']=='ham'].shape[0]/test_set.shape[0] *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test_set[test_set['Label']=='spam'].shape[0]/test_set.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.54104979811575"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[train_set['Label']=='ham'].shape[0]/train_set.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look good we will now move on to cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate all the probabilities required by the algorithm, we will first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need. Essentially, we want to bring the data to this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAGNCAYAAAArVMSZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA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\nwf+JhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('spam first image dataquest.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Case and Punctuation\n",
    "We will begin with removing all the punctuation and bringing every letter to lowe case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before cleaning \n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "train_set['SMS'] = train_set['SMS'].str.replace('\\W',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes  princess  Are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            SMS\n",
       "0   ham                   Yep  by the pretty sculpture\n",
       "1   ham  Yes  princess  Are you going to make me moan \n",
       "2   ham                     Welp apparently he retired"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning\n",
    "train_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set['SMS'] = train_set['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['SMS'].str.isupper().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the vocabulary\n",
    "\n",
    "Let's now move to creating the vocabulary, which in this context means a list with all the unique words in our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set['SMS'] = train_set['SMS'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for rows in train_set['SMS']:\n",
    "    for i in rows:\n",
    "        vocabulary.append(i)\n",
    "vocab_set = set(vocabulary)\n",
    "train_vocab_list = list(vocab_set)\n",
    "len(train_vocab_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are 7,783 unique words in all the messages of our training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use the vocabulary we just created to make the data transformation we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0]* len(train_set['SMS']) for unique_word in train_vocab_list}\n",
    "for index,sms in enumerate(train_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms_df = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 7783)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_label = pd.concat([train_set,word_counts_per_sms_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Constants First\n",
    "\n",
    "We are now done with cleaning the training set, and we can begin creating the spam filter. The Naive Bayes algorithm will need to answer these two probability questions to be able to classify new messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"13.6875pt\" version=\"1.1\" viewBox=\"0 0 287.048495 13.6875\" width=\"287.048495pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<defs>\n",
       "<g>\n",
       "<symbol id=\"glyph0-0\" overflow=\"visible\">\n",
       "<path d=\"M 1.75 -7.84375 L 1.75 -7.640625 C 2.4375 -7.5625 2.609375 -7.46875 2.609375 -7.140625 C 2.609375 -6.953125 2.5625 -6.703125 2.40625 -6.140625 L 1.015625 -1.171875 C 0.796875 -0.390625 0.6875 -0.28125 0 -0.1875 L 0 0 L 2.921875 0 L 2.921875 -0.1875 C 2.28125 -0.265625 2.09375 -0.40625 2.09375 -0.6875 C 2.09375 -0.859375 2.1875 -1.109375 2.265625 -1.4375 L 2.90625 -3.75 C 3.21875 -3.6875 3.484375 -3.65625 3.984375 -3.65625 C 5.046875 -3.65625 5.890625 -3.890625 6.4375 -4.34375 C 6.9375 -4.75 7.265625 -5.40625 7.265625 -6.0625 C 7.265625 -7.21875 6.40625 -7.84375 4.640625 -7.84375 Z M 3.84375 -7.109375 C 3.90625 -7.375 4.125 -7.46875 4.46875 -7.46875 C 5.453125 -7.46875 6.03125 -7.0625 6.03125 -6 C 6.03125 -5.21875 5.703125 -4.6875 5.171875 -4.390625 C 4.796875 -4.171875 4.375 -4.109375 3.640625 -4.109375 C 3.421875 -4.109375 3.359375 -4.109375 3.015625 -4.15625 Z M 3.84375 -7.109375 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph0-1\" overflow=\"visible\">\n",
       "<path d=\"M 6.09375 -8 L 5.8125 -8 C 5.65625 -7.75 5.546875 -7.6875 5.28125 -7.6875 C 5.125 -7.6875 4.984375 -7.734375 4.734375 -7.828125 C 4.46875 -7.9375 4.078125 -7.984375 3.703125 -7.984375 C 2.5625 -7.984375 1.578125 -7.28125 1.578125 -6.03125 C 1.578125 -5.375 1.75 -4.984375 2.46875 -4.21875 C 2.625 -4.0625 2.765625 -3.90625 2.9375 -3.71875 L 3.40625 -3.21875 C 3.953125 -2.609375 4.125 -2.25 4.125 -1.734375 C 4.125 -0.828125 3.484375 -0.203125 2.5625 -0.203125 C 1.546875 -0.203125 0.828125 -1.03125 0.828125 -2.203125 C 0.828125 -2.296875 0.828125 -2.375 0.859375 -2.484375 L 0.609375 -2.515625 L 0.203125 0.1875 L 0.421875 0.1875 C 0.5 -0.09375 0.703125 -0.203125 0.9375 -0.203125 C 1.0625 -0.203125 1.171875 -0.1875 1.5 -0.0625 C 2.046875 0.125 2.375 0.21875 2.75 0.21875 C 4.125 0.21875 5.171875 -0.75 5.171875 -2.125 C 5.171875 -2.90625 4.90625 -3.421875 3.8125 -4.53125 C 2.71875 -5.609375 2.625 -5.8125 2.625 -6.390625 C 2.625 -7.15625 3.140625 -7.59375 3.96875 -7.59375 C 5.140625 -7.59375 5.40625 -6.859375 5.40625 -5.640625 L 5.609375 -5.609375 Z M 6.09375 -8 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph0-2\" overflow=\"visible\">\n",
       "<path d=\"M 2.578125 -5.140625 C 2.59375 -5.1875 2.609375 -5.25 2.609375 -5.25 C 2.609375 -5.265625 2.578125 -5.296875 2.546875 -5.296875 L 0.671875 -5.03125 L 0.703125 -4.84375 L 0.953125 -4.84375 C 1.15625 -4.84375 1.484375 -4.8125 1.484375 -4.53125 C 1.484375 -4.46875 1.421875 -4.15625 1.296875 -3.671875 L -0.078125 1.515625 C -0.234375 2.078125 -0.390625 2.25 -0.90625 2.265625 L -0.90625 2.453125 L 1.53125 2.453125 L 1.53125 2.265625 C 0.96875 2.265625 0.796875 2.1875 0.796875 1.921875 C 0.796875 1.75 1.0625 0.765625 1.265625 -0.078125 C 1.578125 0.078125 1.828125 0.125 2.09375 0.125 C 3.859375 0.125 5.65625 -1.8125 5.65625 -3.796875 C 5.65625 -4.734375 5.171875 -5.296875 4.28125 -5.296875 C 3.5625 -5.296875 2.875 -4.90625 2.234375 -3.9375 Z M 4.578125 -3.75 C 4.578125 -2.921875 4.328125 -2.046875 3.75 -1.234375 C 3.234375 -0.484375 2.65625 -0.09375 2.015625 -0.09375 C 1.6875 -0.09375 1.4375 -0.28125 1.4375 -0.546875 C 1.4375 -0.953125 1.875 -2.515625 2.21875 -3.40625 C 2.5 -4.125 3.203125 -4.78125 3.84375 -4.78125 C 4.375 -4.78125 4.578125 -4.4375 4.578125 -3.75 Z M 4.578125 -3.75 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph0-3\" overflow=\"visible\">\n",
       "<path d=\"M 5.5625 -1.328125 L 5.234375 -0.984375 C 4.875 -0.59375 4.71875 -0.484375 4.609375 -0.484375 C 4.515625 -0.484375 4.4375 -0.5625 4.4375 -0.640625 C 4.4375 -0.890625 4.9375 -2.953125 5.515625 -5 C 5.546875 -5.125 5.5625 -5.140625 5.578125 -5.25 L 5.5 -5.296875 L 4.765625 -5.203125 L 4.734375 -5.171875 L 4.59375 -4.59375 C 4.5 -5.046875 4.15625 -5.296875 3.640625 -5.296875 C 2.046875 -5.296875 0.203125 -3.125 0.203125 -1.265625 C 0.203125 -0.34375 0.734375 0.125 1.40625 0.125 C 2.25 0.125 2.9375 -0.390625 3.84375 -1.75 C 3.59375 -0.765625 3.5625 -0.671875 3.5625 -0.375 C 3.5625 -0.03125 3.703125 0.125 4.046875 0.125 C 4.53125 0.125 4.8125 -0.109375 5.71875 -1.203125 Z M 4.375 -4.328125 C 4.375 -3.484375 4.015625 -2.453125 3.453125 -1.625 C 3.09375 -1.109375 2.53125 -0.453125 1.9375 -0.453125 C 1.5 -0.453125 1.21875 -0.6875 1.21875 -1.34375 C 1.21875 -2.09375 1.625 -3.171875 2.140625 -3.921875 C 2.640625 -4.65625 3.171875 -5.03125 3.703125 -5.03125 C 4.125 -5.03125 4.375 -4.75 4.375 -4.328125 Z M 4.375 -4.328125 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph0-4\" overflow=\"visible\">\n",
       "<path d=\"M 8.453125 -1.265625 L 8.265625 -1.40625 L 8.015625 -1.09375 C 7.65625 -0.640625 7.4375 -0.453125 7.234375 -0.453125 C 7.140625 -0.453125 7.09375 -0.515625 7.09375 -0.640625 C 7.09375 -0.703125 7.140625 -0.90625 7.21875 -1.1875 L 8.03125 -4.203125 C 8.046875 -4.265625 8.0625 -4.453125 8.0625 -4.53125 C 8.0625 -4.96875 7.8125 -5.296875 7.375 -5.296875 C 7.125 -5.296875 6.90625 -5.234375 6.609375 -5.046875 C 6.03125 -4.6875 5.53125 -4.078125 4.6875 -2.75 C 5.015625 -3.671875 5.171875 -4.34375 5.171875 -4.578125 C 5.171875 -5 4.9375 -5.296875 4.453125 -5.296875 C 3.71875 -5.296875 2.875 -4.5 1.8125 -2.765625 L 2.515625 -5.265625 L 2.46875 -5.296875 L 0.53125 -4.921875 L 0.53125 -4.734375 L 0.828125 -4.734375 C 1.15625 -4.734375 1.3125 -4.640625 1.3125 -4.46875 C 1.3125 -4.3125 1.140625 -3.328125 0.65625 -1.734375 L 0.140625 0 L 1.046875 0 C 1.625 -1.890625 1.78125 -2.328125 2.203125 -2.953125 C 2.875 -3.96875 3.578125 -4.671875 3.984375 -4.671875 C 4.140625 -4.671875 4.25 -4.5625 4.25 -4.375 C 4.25 -4.21875 3.953125 -2.9375 3.4375 -1.109375 L 3.109375 0 L 4.015625 0 C 4.46875 -1.84375 4.71875 -2.4375 5.296875 -3.265625 C 5.90625 -4.109375 6.515625 -4.671875 6.875 -4.671875 C 7.015625 -4.671875 7.109375 -4.5625 7.109375 -4.421875 C 7.109375 -4.359375 7.09375 -4.203125 7.03125 -3.953125 L 6.34375 -1.234375 C 6.21875 -0.765625 6.1875 -0.5625 6.1875 -0.4375 C 6.1875 -0.078125 6.34375 0.109375 6.65625 0.109375 C 7.21875 0.109375 7.75 -0.28125 8.390625 -1.171875 Z M 8.453125 -1.265625 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph0-5\" overflow=\"visible\">\n",
       "<path d=\"M 4.84375 -5.109375 C 4.84375 -5.25 4.8125 -5.28125 4.734375 -5.28125 C 4.6875 -5.28125 4.640625 -5.25 4.578125 -5.15625 L 2.28125 -1.515625 C 2.234375 -2.5625 2.0625 -4.0625 1.890625 -4.890625 C 1.8125 -5.265625 1.796875 -5.296875 1.671875 -5.296875 C 1.578125 -5.296875 1.46875 -5.25 1.3125 -5.203125 C 0.953125 -5.109375 0.546875 -5.0625 0.1875 -5 L 0.1875 -4.84375 L 0.515625 -4.84375 C 0.859375 -4.84375 0.96875 -4.78125 1.078125 -4.34375 C 1.21875 -3.765625 1.359375 -2.484375 1.40625 -1.4375 L 1.453125 -0.34375 C 1.46875 0.125 1.5 0.21875 1.609375 0.21875 C 1.734375 0.21875 1.9375 -0.078125 2.375 -0.90625 C 2.609375 -1.34375 2.8125 -1.734375 3.03125 -2.09375 L 4.109375 -3.921875 L 4.453125 -0.203125 C 4.46875 0.109375 4.5 0.21875 4.578125 0.21875 C 4.6875 0.21875 4.796875 0.09375 5.125 -0.296875 L 5.234375 -0.4375 C 6.890625 -2.453125 7.78125 -3.859375 7.78125 -4.625 C 7.78125 -5 7.515625 -5.296875 7.15625 -5.296875 C 6.890625 -5.296875 6.6875 -5.109375 6.6875 -4.921875 C 6.6875 -4.75 6.75 -4.609375 6.9375 -4.421875 C 7.125 -4.25 7.203125 -4.15625 7.203125 -4.015625 C 7.203125 -3.484375 6.796875 -2.859375 5.21875 -0.890625 Z M 4.84375 -5.109375 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph1-0\" overflow=\"visible\">\n",
       "<path d=\"M 4.15625 11.578125 C 3.28125 10.878906 2.632812 10.003906 2.21875 8.953125 C 1.8125 7.910156 1.609375 6.789062 1.609375 5.59375 C 1.609375 4.394531 1.8125 3.269531 2.21875 2.21875 C 2.632812 1.164062 3.28125 0.300781 4.15625 -0.375 C 4.15625 -0.394531 4.175781 -0.40625 4.21875 -0.40625 L 4.34375 -0.40625 C 4.363281 -0.40625 4.378906 -0.394531 4.390625 -0.375 C 4.410156 -0.351562 4.421875 -0.332031 4.421875 -0.3125 C 4.421875 -0.28125 4.414062 -0.257812 4.40625 -0.25 C 4.019531 0.125 3.695312 0.539062 3.4375 1 C 3.175781 1.457031 2.96875 1.929688 2.8125 2.421875 C 2.664062 2.921875 2.554688 3.4375 2.484375 3.96875 C 2.421875 4.507812 2.390625 5.054688 2.390625 5.609375 C 2.390625 8.191406 3.0625 10.132812 4.40625 11.4375 C 4.414062 11.445312 4.421875 11.46875 4.421875 11.5 C 4.421875 11.519531 4.410156 11.539062 4.390625 11.5625 C 4.378906 11.582031 4.363281 11.59375 4.34375 11.59375 L 4.21875 11.59375 C 4.175781 11.59375 4.15625 11.585938 4.15625 11.578125 Z M 4.15625 11.578125 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph2-0\" overflow=\"visible\">\n",
       "<path d=\"M 1.59375 0.171875 L 1.59375 -8.109375 L 0.796875 -8.109375 L 0.796875 0.171875 Z M 1.59375 0.171875 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph2-1\" overflow=\"visible\">\n",
       "<path d=\"M 1 1.6875 C 1.828125 1.296875 2.34375 0.546875 2.34375 -0.1875 C 2.34375 -0.796875 1.921875 -1.21875 1.375 -1.21875 C 0.953125 -1.21875 0.65625 -0.953125 0.65625 -0.546875 C 0.65625 -0.125 0.90625 0.078125 1.359375 0.078125 C 1.484375 0.078125 1.609375 0.03125 1.703125 0.03125 C 1.796875 0.03125 1.875 0.09375 1.875 0.1875 C 1.875 0.578125 1.53125 1.015625 0.875 1.46875 Z M 1 1.6875 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph2-2\" overflow=\"visible\">\n",
       "<path d=\"M 2.171875 -0.515625 C 2.171875 -0.875 1.859375 -1.203125 1.515625 -1.203125 C 1.140625 -1.203125 0.84375 -0.90625 0.84375 -0.53125 C 0.84375 -0.15625 1.125 0.125 1.5 0.125 C 1.859375 0.125 2.171875 -0.171875 2.171875 -0.515625 Z M 2.171875 -0.515625 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph2-3\" overflow=\"visible\">\n",
       "<path d=\"M 7.71875 -1.015625 C 7 -1.015625 6.40625 -1.625 5.640625 -2.90625 L 5.640625 -2.9375 C 5.96875 -3.484375 6.640625 -4.15625 7.71875 -4.15625 L 7.71875 -5.15625 C 6.5 -5.15625 5.953125 -4.390625 5.40625 -3.390625 C 4.265625 -4.9375 3.65625 -5.15625 2.78125 -5.15625 C 2.09375 -5.15625 0.484375 -4.609375 0.484375 -2.40625 C 0.484375 -0.75 1.578125 0 2.609375 0 C 3.75 0 4.578125 -0.640625 5.109375 -1.734375 C 5.859375 -0.640625 6.546875 0 7.71875 0 Z M 4.84375 -2.171875 C 4.53125 -1.734375 3.953125 -1.015625 2.875 -1.015625 C 1.828125 -1.015625 1.21875 -2 1.21875 -3.03125 C 1.21875 -3.796875 1.734375 -4.453125 2.40625 -4.453125 C 3.234375 -4.453125 3.984375 -3.640625 4.84375 -2.203125 Z M 4.84375 -2.171875 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph2-4\" overflow=\"visible\">\n",
       "<path d=\"M 2.4375 -3.03125 C 2.4375 -3.421875 2.109375 -3.75 1.734375 -3.75 C 1.328125 -3.75 1 -3.390625 1 -3.03125 C 1 -2.671875 1.328125 -2.3125 1.734375 -2.3125 C 2.109375 -2.3125 2.4375 -2.65625 2.4375 -3.03125 Z M 2.4375 -3.03125 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph3-0\" overflow=\"visible\">\n",
       "<path d=\"M 3.359375 0 L 3.359375 -0.125 C 2.71875 -0.125 2.546875 -0.28125 2.546875 -0.640625 L 2.546875 -5.734375 L 2.46875 -5.75 L 0.9375 -4.984375 L 0.9375 -4.859375 L 1.171875 -4.953125 C 1.328125 -5 1.46875 -5.046875 1.5625 -5.046875 C 1.734375 -5.046875 1.8125 -4.921875 1.8125 -4.625 L 1.8125 -0.8125 C 1.8125 -0.34375 1.640625 -0.15625 1 -0.125 L 1 0 Z M 3.359375 0 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph3-1\" overflow=\"visible\">\n",
       "<path d=\"M 4.03125 -1.171875 L 3.921875 -1.21875 C 3.640625 -0.734375 3.453125 -0.640625 3.09375 -0.640625 L 1.109375 -0.640625 L 2.515625 -2.140625 C 3.265625 -2.953125 3.609375 -3.578125 3.609375 -4.25 C 3.609375 -5.09375 2.984375 -5.75 2.03125 -5.75 C 0.984375 -5.75 0.4375 -5.0625 0.25 -4.0625 L 0.4375 -4.015625 C 0.78125 -4.859375 1.078125 -5.125 1.6875 -5.125 C 2.40625 -5.125 2.875 -4.703125 2.875 -3.921875 C 2.875 -3.203125 2.5625 -2.546875 1.765625 -1.71875 L 0.25 -0.109375 L 0.25 0 L 3.578125 0 Z M 4.03125 -1.171875 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph3-2\" overflow=\"visible\">\n",
       "<path d=\"M 5.421875 -2.71875 L 5.421875 -3.28125 L 0.40625 -3.28125 L 0.40625 -2.71875 Z M 5.421875 -1.015625 L 5.421875 -1.578125 L 0.40625 -1.578125 L 0.40625 -1.015625 Z M 5.421875 -1.015625 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph4-0\" overflow=\"visible\">\n",
       "<path d=\"M 3.921875 -1 C 3.859375 -0.921875 3.796875 -0.84375 3.734375 -0.78125 C 3.484375 -0.453125 3.34375 -0.328125 3.21875 -0.328125 C 3.109375 -0.328125 3.078125 -0.40625 3.078125 -0.484375 C 3.078125 -0.546875 3.109375 -0.6875 3.203125 -1 L 3.671875 -2.71875 C 3.734375 -2.90625 3.765625 -3.078125 3.765625 -3.234375 C 3.765625 -3.546875 3.578125 -3.75 3.203125 -3.75 C 2.671875 -3.75 2.09375 -3.25 1.25 -1.875 L 1.8125 -3.734375 L 1.78125 -3.75 C 1.328125 -3.65625 1.09375 -3.625 0.40625 -3.484375 L 0.40625 -3.359375 C 0.828125 -3.34375 0.953125 -3.296875 0.953125 -3.125 C 0.953125 -3.078125 0.9375 -3.015625 0.9375 -2.984375 L 0.125 0 L 0.765625 0 C 1.15625 -1.34375 1.21875 -1.546875 1.609375 -2.109375 C 2.140625 -2.90625 2.53125 -3.328125 2.875 -3.328125 C 3 -3.328125 3.078125 -3.234375 3.078125 -3.078125 C 3.078125 -2.96875 3.015625 -2.671875 2.953125 -2.40625 L 2.578125 -1.015625 C 2.46875 -0.578125 2.4375 -0.46875 2.4375 -0.390625 C 2.4375 -0.0625 2.625 0.078125 2.84375 0.078125 C 3.25 0.078125 3.453125 -0.09375 4.03125 -0.890625 Z M 3.921875 -1 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph4-1\" overflow=\"visible\">\n",
       "<path d=\"M 2.25 -5.09375 C 2.25 -5.34375 2.046875 -5.5625 1.828125 -5.5625 C 1.59375 -5.5625 1.421875 -5.375 1.421875 -5.125 C 1.421875 -4.84375 1.578125 -4.671875 1.828125 -4.671875 C 2.046875 -4.671875 2.25 -4.859375 2.25 -5.09375 Z M 1.890625 -0.96875 C 1.53125 -0.484375 1.3125 -0.3125 1.171875 -0.3125 C 1.109375 -0.3125 1.0625 -0.34375 1.0625 -0.4375 C 1.0625 -0.546875 1.09375 -0.671875 1.140625 -0.8125 L 1.9375 -3.734375 L 1.90625 -3.75 C 1.046875 -3.59375 0.875 -3.5625 0.546875 -3.546875 L 0.546875 -3.40625 C 1 -3.390625 1.09375 -3.375 1.09375 -3.203125 C 1.09375 -3.140625 1.0625 -2.984375 1.015625 -2.828125 L 0.609375 -1.3125 C 0.484375 -0.84375 0.421875 -0.546875 0.421875 -0.375 C 0.421875 -0.0625 0.546875 0.09375 0.828125 0.09375 C 1.265625 0.09375 1.53125 -0.15625 2 -0.875 Z M 1.890625 -0.96875 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph5-0\" overflow=\"visible\">\n",
       "<path d=\"M 0.53125 11.59375 C 0.46875 11.59375 0.4375 11.5625 0.4375 11.5 C 0.4375 11.46875 0.445312 11.445312 0.46875 11.4375 C 0.976562 10.9375 1.378906 10.367188 1.671875 9.734375 C 1.972656 9.109375 2.1875 8.445312 2.3125 7.75 C 2.4375 7.050781 2.5 6.332031 2.5 5.59375 C 2.5 3 1.820312 1.050781 0.46875 -0.25 C 0.445312 -0.257812 0.4375 -0.28125 0.4375 -0.3125 C 0.4375 -0.375 0.46875 -0.40625 0.53125 -0.40625 L 0.671875 -0.40625 C 0.691406 -0.40625 0.707031 -0.394531 0.71875 -0.375 C 1.601562 0.300781 2.25 1.164062 2.65625 2.21875 C 3.070312 3.269531 3.28125 4.394531 3.28125 5.59375 C 3.28125 6.789062 3.070312 7.910156 2.65625 8.953125 C 2.25 10.003906 1.601562 10.878906 0.71875 11.578125 C 0.707031 11.585938 0.691406 11.59375 0.671875 11.59375 Z M 0.53125 11.59375 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "<symbol id=\"glyph6-0\" overflow=\"visible\">\n",
       "<path d=\"M 0.484375 12.015625 L 0.484375 11.546875 C 1.410156 11.546875 1.875 11.257812 1.875 10.6875 L 1.875 1.3125 C 1.875 0.75 1.410156 0.46875 0.484375 0.46875 L 0.484375 0 L 10.4375 0 L 10.4375 0.46875 C 9.5 0.46875 9.03125 0.75 9.03125 1.3125 L 9.03125 10.6875 C 9.03125 11.257812 9.5 11.546875 10.4375 11.546875 L 10.4375 12.015625 L 6.296875 12.015625 L 6.296875 11.546875 C 7.222656 11.546875 7.6875 11.257812 7.6875 10.6875 L 7.6875 0.46875 L 3.21875 0.46875 L 3.21875 10.6875 C 3.21875 11.257812 3.6875 11.546875 4.625 11.546875 L 4.625 12.015625 Z M 0.484375 12.015625 \" style=\"stroke:none;\"/>\n",
       "</symbol>\n",
       "</g>\n",
       "</defs>\n",
       "<g id=\"surface1\">\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"0.667969\" xlink:href=\"#glyph0-0\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"7.644531\" xlink:href=\"#glyph1-0\" y=\"0.920068\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"13.207031\" xlink:href=\"#glyph0-1\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"21.542969\" xlink:href=\"#glyph0-2\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"28.328125\" xlink:href=\"#glyph0-3\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"35.238281\" xlink:href=\"#glyph0-4\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"44.230469\" xlink:href=\"#glyph2-0\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"46.96875\" xlink:href=\"#glyph0-5\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"54.953125\" xlink:href=\"#glyph3-0\" y=\"12.265625\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"58.796875\" xlink:href=\"#glyph2-1\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"66.285156\" xlink:href=\"#glyph0-5\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"74.957031\" xlink:href=\"#glyph3-1\" y=\"12.265625\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"79.472656\" xlink:href=\"#glyph2-1\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"86.304688\" xlink:href=\"#glyph2-2\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"88.964844\" xlink:href=\"#glyph2-2\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"91.628906\" xlink:href=\"#glyph2-2\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"94.476562\" xlink:href=\"#glyph2-1\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"101.964844\" xlink:href=\"#glyph0-5\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"110.761719\" xlink:href=\"#glyph4-0\" y=\"10.859375\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"115.484375\" xlink:href=\"#glyph5-0\" y=\"0.920068\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"122.945312\" xlink:href=\"#glyph2-3\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"135.328125\" xlink:href=\"#glyph0-0\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"142.308594\" xlink:href=\"#glyph1-0\" y=\"0.920068\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"147.871094\" xlink:href=\"#glyph0-1\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"156.203125\" xlink:href=\"#glyph0-2\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"162.992188\" xlink:href=\"#glyph0-3\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"169.902344\" xlink:href=\"#glyph0-4\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"179.238281\" xlink:href=\"#glyph5-0\" y=\"0.920068\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"186.183594\" xlink:href=\"#glyph2-4\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"192.808594\" xlink:href=\"#glyph6-0\" y=\"0.516577\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"203.976562\" xlink:href=\"#glyph4-1\" y=\"13.59375\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"210.097656\" xlink:href=\"#glyph3-2\" y=\"13.59375\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"218.863281\" xlink:href=\"#glyph3-0\" y=\"13.59375\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"204.273438\" xlink:href=\"#glyph4-0\" y=\"3.75\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"225.363281\" xlink:href=\"#glyph0-0\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"232.339844\" xlink:href=\"#glyph1-0\" y=\"0.920068\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"237.917969\" xlink:href=\"#glyph0-5\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"246.417969\" xlink:href=\"#glyph4-1\" y=\"12.078125\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"249.011719\" xlink:href=\"#glyph2-0\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"251.734375\" xlink:href=\"#glyph0-1\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"260.070312\" xlink:href=\"#glyph0-2\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"266.855469\" xlink:href=\"#glyph0-3\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"273.765625\" xlink:href=\"#glyph0-4\" y=\"9.554688\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use x=\"283.105469\" xlink:href=\"#glyph5-0\" y=\"0.920068\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "SVG('spam seond image.svg')\n",
    "#SVG('spam second image.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same applies to ham \n",
    "\n",
    "Also, to calculate P($w_{i}$|Spam) and P($w_{i}$|ham) inside the formulas above, we will need to use these equations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P($w_{i}$|Spam) = N($w_{i}|Spam$) + alpha/N($_{Spam}$) + alpha * N($_{Vocabulary}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same applies to ham\n",
    "\n",
    "Some of the terms in the four equations above will have the same value for every new message.We can calculate the value of these terms once and avoid doing the computations again when new messages comes in. Below, we will use our training set to calculate:\n",
    "- P(Spam) and P(Ham)\n",
    "- N($_{Spam}$),N($_{Ham}$,N($_{Vocalbulary)}$\n",
    "\n",
    "We will also use Laplace smoothning and set alpha to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_label_set = train_label\n",
    "# calculating the probability of non spam messages in the data set P(Spam)and P(Ham)\n",
    "p_ham= len(train_label_set[train_label_set['Label']=='ham'])/len(train_label_set)\n",
    "p_spam = len(train_label_set[train_label_set['Label']=='spam'])/len(train_label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Isolating spam and ham messages \n",
    "train_spam = train_label_set[train_label_set['Label']=='spam']\n",
    "train_ham = train_label_set[train_label_set['Label']== 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15190"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_spam = (train_spam['SMS'].apply(len)).sum() # sum numbers of spam words\n",
    "n_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ham_len = train_ham['SMS'].apply(len) #numbers of ham words\n",
    "n_ham = train_ham_len.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numbers of vocabulary\n",
    "n_vocabulary = len(train_vocab_list)\n",
    "n_vocabulary\n",
    "# Laplace smoothning\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, why, haven, t, you, replied, to, my,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spam</td>\n",
       "      <td>[congrats, 2, mobile, 3g, videophones, r, your...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                                SMS  0  00  000  \\\n",
       "16  spam  [freemsg, why, haven, t, you, replied, to, my,...  0   0    0   \n",
       "18  spam  [congrats, 2, mobile, 3g, videophones, r, your...  0   0    0   \n",
       "\n",
       "    000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "16       0             0     0            0   0 ...       0    0          0   \n",
       "18       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "    zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "16     0      0  0   0  0    0  0  \n",
       "18     0      0  0   0  0    0  0  \n",
       "\n",
       "[2 rows x 7785 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spam.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word_spam:0 for unique_word_spam in train_vocab_list}\n",
    "parameters_ham = {unique_word: 0 for unique_word in train_vocab_list}\n",
    "# calculate parameters\n",
    "for word in train_vocab_list:\n",
    "    n_word_given_spam = train_spam[word].sum() # train_spam already defined in a cell above\n",
    "    p_word_given_spam = (n_word_given_spam +alpha)/((n_spam)+(alpha * n_vocabulary))\n",
    "    parameters_spam[word]= p_word_given_spam\n",
    "for word in train_vocab_list:\n",
    "    n_word_given_ham = train_ham[word].sum() # train_ham already defined in a cell above\n",
    "    p_word_given_ham = (n_word_given_ham+alpha)/((n_ham)+(alpha*n_vocabulary))\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying A New Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our parameters calculated, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "- Takes in as input a new message ($w_{1}$,$w_{2}$,$w_{3}$,.....,$w_{n}$)\n",
    "- Calculates P(Spam|$w_{1}$,$w_{2}$,....,$w_{n}$)\n",
    "- Compares the values of P(Spam|$w_{1}$,$w_{2}$,...,$w_{n}$) and P(Ham|$w_{1}$,$w_{2}$,...,$w_{n}$)\n",
    "- If P(Ham|$w_{1}$,$w_{2}$,...,$w_{n}$) > P(Spam|$w_{1}$,$w_{2}$,...,$w_{n}$), then the message is classified as ham\n",
    "- If P(Ham|$w_{1}$,$w_{2}$,...,$w_{n}$) < P(Spam|$w_{1}$,$w_{2}$,...,$w_{n}$), then the message is classdified as spam\n",
    "- If P(Ham|$w_{1}$,$w_{2}$,...,$w_{n}$) == P(Spam|$w_{1}$,$w_{2}$,...,$w_{n}$), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re # regex or regular expression\n",
    "def classify(message):\n",
    "    message = re.sub('\\W',' ',message)\n",
    "    message = message.lower() # to avoid discrepancies due to capitalization\n",
    "    message = message.split() # split each string at white space into one single list at \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word] \n",
    "    for word in message:\n",
    "            if word in parameters_ham:\n",
    "                p_ham_given_message *= parameters_ham[word]\n",
    "    p_ham_given_message *= p_ham\n",
    "    print('P(Spam|message):',p_spam_given_message)\n",
    "    print('P(Ham|message):',p_ham_given_message)\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Hey humam there is equal probabilities,please can you use your brain to classidy this!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.6761312954755437e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('Winner!! This is the secret code to unlock the money: C3421')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.1912275500820184e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurung the Spam Filter's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two results above looks promising, but let us see how well the filter does on our test set,wgich has 1,114 messages.\n",
    "\n",
    "We will start by writing a function that returns classification labels instead of printing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    message = re.sub('\\W',' ',message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function to measure the accuracy of our spam filter to find out how well our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1100\n",
      "Incorrect: 14\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set)\n",
    "for index,rows in test_set.iterrows():\n",
    "    if rows['Label'] == rows['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "print('Correct:',correct)\n",
    "print('Incorrect:',total-correct)\n",
    "print('Accuracy:',correct/total)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is close to 98.74% which is really good. Our spam filter looked at 1,114 messages that has not seem in training, and classified 1,100 correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking rows that have incorrect labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "114  spam  Not heard from U4 a while. Call me now am here...   \n",
       "135  spam  More people are dogging in your area now. Call...   \n",
       "152   ham                  Unlimited texts. Limited minutes.   \n",
       "159   ham                                       26th OF JULY   \n",
       "284   ham                             Nokia phone is lovly..   \n",
       "293   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "302   ham                   No calls..messages..missed calls   \n",
       "319   ham  We have sent JD for Customer Service cum Accou...   \n",
       "504  spam  Oh my god! I've found your number again! I'm s...   \n",
       "546  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "741  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "876  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "885  spam                                      2/2 146tf150p   \n",
       "953  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                      predicted  \n",
       "114                         ham  \n",
       "135                         ham  \n",
       "152                        spam  \n",
       "159                        spam  \n",
       "284                        spam  \n",
       "293  needs human classification  \n",
       "302                        spam  \n",
       "319                        spam  \n",
       "504                         ham  \n",
       "546                         ham  \n",
       "741                         ham  \n",
       "876                         ham  \n",
       "885                         ham  \n",
       "953                         ham  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[test_set['Label']!=test_set['predicted']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some spam messages contain almost similar messages as that of ham the algorithm classified them as  ham and vice-versa. Also we have only one label that needs human classification, the message ` A Boy loved a gal. He propsd bt she didnt mind..` has equal probability with that of ham as it contains all similar word in ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making the algorithm more sensitive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will not apply the lowe string function to the message, we will allow variations in lowe characters and upper characters and see if the model will underperform or overperform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_complex(message):\n",
    "    messsage = re.sub('\\W',' ',message)\n",
    "    message = message.split()\n",
    "    p_spam_given_new_message = p_spam\n",
    "    p_ham_given_new_message = p_ham\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_new_message *= parameters_spam[word]\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_new_message *= parameters_ham[word]\n",
    "    if p_spam_given_new_message > p_ham_given_new_message:\n",
    "        return 'spam '\n",
    "    elif p_ham_given_new_message > p_spam_given_new_message:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set['complex_predictions'] = test_set['SMS'].apply(classify_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex Correct: 960\n",
      "Incorrect: 154\n",
      "Accuracy: 0.8617594254937163\n"
     ]
    }
   ],
   "source": [
    "complex_correct = 0\n",
    "total_complex = len(test_set)\n",
    "for index,rows in test_set.iterrows():\n",
    "    if rows['Label'] == rows['complex_predictions']:\n",
    "        complex_correct += 1\n",
    "\n",
    "print('Complex Correct:',complex_correct)\n",
    "print('Incorrect:',total_complex-complex_correct)\n",
    "print('Accuracy:',complex_correct/total_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The accuracy is close to 86%, which is really good. Our benchmark for accuracy is 80% which the algorithm surpassed, this hows that the model is good enough to be used. The complex filter looked at 1,114 messages that it has not seen before and classified 960 correctly despite the fact that there were variations in capitalization of words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
